{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_reduction(df, new_freq):\n",
    "    mean_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, df.shape[1], new_freq):\n",
    "        # Taking the mean of every 500 columns\n",
    "        mean_cols = df.iloc[:, i:i+new_freq].mean(axis=1)\n",
    "        # Appending the new columns to mean_df\n",
    "        mean_df = pd.concat([mean_df, mean_cols], axis=1)\n",
    "        \n",
    "    return mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_x_train = []\n",
    "collected_x_test = []\n",
    "\n",
    "lower_freq_x = freq_reduction(pd.DataFrame(My_X_test_n_rs), 50).to_numpy()\n",
    "\n",
    "for i in range(6):\n",
    "    collected_x_train.append(lower_freq_x[4*i].tolist().append(i+1))\n",
    "    collected_x_train.append(lower_freq_x[4*i+3].tolist().append(i+1))\n",
    "    collected_x_test.append(lower_freq_x[4*i+2].tolist())\n",
    "    collected_x_test.append(lower_freq_x[4*i+1].tolist())\n",
    "\n",
    "first_x_train = pd.DataFrame(collected_x_train[0:2]).to_csv()\n",
    "second_x_train = pd.DataFrame(collected_x_train[2:4]).to_csv()\n",
    "third_x_train = pd.DataFrame(collected_x_train[4:6]).to_csv()\n",
    "fourth_x_train = pd.DataFrame(collected_x_train[6:8]).to_csv()\n",
    "fifth_x_train = pd.DataFrame(collected_x_train[8:10]).to_csv()\n",
    "sixth_x_train = pd.DataFrame(collected_x_train[10:12]).to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer was: [1, 1, 2, 2, 3, 3]\n",
      "Model predicted: [1, 2, 3, 4, 5, 6]\n",
      "Correct answer was: [4, 4, 5, 5, 6, 6]\n",
      "Model predicted: [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "Total Accuracy turned out to be 16.666666666666664%\n"
     ]
    }
   ],
   "source": [
    "total_accuracies = 0\n",
    "total_iterations = 0\n",
    "num_test_splits = 2\n",
    "\n",
    "for i in range(num_test_splits):\n",
    "    lot_size = 12//num_test_splits\n",
    "    csv_tsfel_test = pd.DataFrame(collected_x_test[lot_size*i:lot_size*(i+1)]).to_csv()\n",
    "    \n",
    "    query = f'''\n",
    "    You are an activity classification model.\n",
    "    \n",
    "    **Instructions:**\n",
    "    1. **Train** a Decision Tree model using the following training data provided in csv format, which includes 6 classes with 30 feature columns and 1 label column at the end.\n",
    "    2. **Predict** the class for each row in the test data, which consists of {lot_size} rows with 30 feature columns only. The label has to be predicted.\n",
    "    3. **Output**: Provide only the {lot_size} predicted activity labels as a single line of space-separated integers. Do not include any additional text, explanations, or code.\n",
    "    \n",
    "    **Training Data:** for first class\n",
    "    {first_x_train}\n",
    "\n",
    "    **Training Data:** for second class\n",
    "    {second_x_train}\n",
    "\n",
    "    **Training Data:** for third class\n",
    "    {third_x_train}\n",
    "\n",
    "    **Training Data:** for fourth class\n",
    "    {fourth_x_train}\n",
    "\n",
    "    **Training Data:** for fifth class\n",
    "    {fifth_x_train}\n",
    "\n",
    "    **Training Data:** for sixth class\n",
    "    {sixth_x_train}\n",
    "    \n",
    "    **Test Data:**\n",
    "    {csv_tsfel_test}\n",
    "    '''\n",
    "\n",
    "    # To use Groq LLMs \n",
    "    model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "    toggle = False\n",
    "    while not toggle:\n",
    "        try:\n",
    "            llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=1)\n",
    "            answer = llm.invoke(query)\n",
    "            # print(f'Correct Answer was {y_test}')\n",
    "            \n",
    "            \n",
    "            answer = list(map(int, answer.content.split()))\n",
    "            res = 0\n",
    "            correct_answers = [3*i+1,3*i+1,3*i+2,3*i+2,3*i+3,3*i+3]\n",
    "            print(f\"Correct answer was: {correct_answers}\")\n",
    "            print(f'Model predicted: {answer}')\n",
    "            \n",
    "            for j in range(lot_size):\n",
    "                if correct_answers[j] == answer[j]:\n",
    "                    res += 1\n",
    "            accuracy = res/lot_size\n",
    "            \n",
    "            total_accuracies += accuracy\n",
    "            total_iterations += 1\n",
    "            toggle = True\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "print(f'\\nTotal Accuracy turned out to be {100*total_accuracies/total_iterations}%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
